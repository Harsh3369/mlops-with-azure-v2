{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from azureml.core import Workspace\n",
        "import os\n",
        "import io\n",
        "from azure.storage.blob import BlobServiceClient\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from xgboost import XGBClassifier\n",
        "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 1,
          "data": {
            "text/plain": "True"
          },
          "metadata": {}
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1723015394795
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_dataframe_to_blob(dataframe, container_name, blob_name):\n",
        "    # Get connection string from environment variables\n",
        "    connection_string = os.getenv('connection_string')\n",
        "    if not connection_string:\n",
        "        raise ValueError(\"connection_string is not set in the .env file\")\n",
        "    # Initialize BlobServiceClient\n",
        "    try:\n",
        "        blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n",
        "        print(\"Successfully connected to Azure Blob Storage.\")\n",
        "    except ValueError as e:\n",
        "        print(f\"Error initializing BlobServiceClient: {e}\")\n",
        "        raise\n",
        "    # Ensure the container exists\n",
        "    try:\n",
        "        container_client = blob_service_client.get_container_client(container_name)\n",
        "        if not container_client.exists():\n",
        "            container_client.create_container()\n",
        "            print(f\"Created container: {container_name}\")\n",
        "        else:\n",
        "            print(f\"Container {container_name} already exists.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error creating/getting container client: {e}\")\n",
        "        raise\n",
        "    # Convert dataframe to CSV string\n",
        "    csv_data = dataframe.to_csv(index=False)\n",
        "    # Upload CSV string to blob storage\n",
        "    try:\n",
        "        blob_client = container_client.get_blob_client(blob_name)\n",
        "        blob_client.upload_blob(csv_data, overwrite=True)\n",
        "        print(f\"Uploaded {blob_name} to blob storage in container {container_name}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error uploading blob: {e}\")\n",
        "        raise\n",
        "\n",
        "\n",
        "def load_dataframe_from_blob(container_name, blob_name):\n",
        "    \"\"\"\n",
        "    Loads a CSV file from Azure Blob Storage into a Pandas DataFrame.\n",
        "    Args:\n",
        "        container_name (str): The name of the Azure Blob Storage container.\n",
        "        blob_name (str): The name of the blob to download.\n",
        "    Returns:\n",
        "        pandas.DataFrame: The loaded DataFrame.\n",
        "    \"\"\"\n",
        "    # Get connection string from environment variables\n",
        "    connection_string = os.getenv('connection_string')\n",
        "    if not connection_string:\n",
        "        raise ValueError(\"connection_string is not set in the .env file\")\n",
        "    # Initialize BlobServiceClient\n",
        "    try:\n",
        "        blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n",
        "        print(\"Successfully connected to Azure Blob Storage.\")\n",
        "    except ValueError as e:\n",
        "        print(f\"Error initializing BlobServiceClient: {e}\")\n",
        "        raise\n",
        "    # Get blob client\n",
        "    try:\n",
        "        blob_client = blob_service_client.get_blob_client(container=container_name, blob=blob_name)\n",
        "    except Exception as e:\n",
        "        print(f\"Error getting blob client: {e}\")\n",
        "        raise\n",
        "    # Download blob content to a byte stream\n",
        "    download_stream = blob_client.download_blob()\n",
        "    blob_data = download_stream.readall()\n",
        "    # Create a Pandas DataFrame from the byte stream\n",
        "    df = pd.read_csv(io.BytesIO(blob_data))\n",
        "    return df"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1723015395056
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "connection_string = os.getenv('connection_string')\n",
        "container_name = os.getenv('container_name')\n",
        "blob_name = os.getenv('train_blob_name')"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1723015395238
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_processed = load_dataframe_from_blob('processed-files','processed_test_df.csv')\n",
        "print(df_train_processed.shape)\n",
        "print('')\n",
        "df_train_processed.head()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Successfully connected to Azure Blob Storage.\n(151655, 11)\n\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/plain": "                                UserID  basket_icon_click  basket_add_list  \\\n0  9d24-25k4-47889d24-25k4-494b-398124                  0                0   \n1  7732-1k58-47887732-1k58-4475-679678                  0                0   \n2  94k2-632j-471394k2-632j-4b4j-228160                  0                0   \n3  jdd8-419d-4714jdd8-419d-4198-674376                  0                0   \n4  7473-7595-47147473-7595-4757-227547                  0                0   \n\n   basket_add_detail  image_picker  list_size_dropdown  \\\n0                  0             0                   0   \n1                  0             0                   0   \n2                  0             0                   0   \n3                  1             0                   0   \n4                  0             0                   0   \n\n   closed_minibasket_click  sign_in  saw_checkout  saw_homepage  ordered  \n0                        0        0             0             0        0  \n1                        0        0             0             0        0  \n2                        0        0             0             0        0  \n3                        0        0             0             0        0  \n4                        0        0             0             0        0  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>UserID</th>\n      <th>basket_icon_click</th>\n      <th>basket_add_list</th>\n      <th>basket_add_detail</th>\n      <th>image_picker</th>\n      <th>list_size_dropdown</th>\n      <th>closed_minibasket_click</th>\n      <th>sign_in</th>\n      <th>saw_checkout</th>\n      <th>saw_homepage</th>\n      <th>ordered</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>9d24-25k4-47889d24-25k4-494b-398124</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7732-1k58-47887732-1k58-4475-679678</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>94k2-632j-471394k2-632j-4b4j-228160</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>jdd8-419d-4714jdd8-419d-4198-674376</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7473-7595-47147473-7595-4757-227547</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1723015395505
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_processed[\"ordered\"].value_counts"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 8,
          "data": {
            "text/plain": "<bound method IndexOpsMixin.value_counts of 0         0\n1         0\n2         0\n3         0\n4         0\n         ..\n151650    0\n151651    0\n151652    0\n151653    0\n151654    0\nName: ordered, Length: 151655, dtype: int64>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1723016061423
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df_train_processed.drop(columns=['UserID','ordered'])\n",
        "y = df_train_processed['ordered']\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42,stratify=y)\n"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1723015395699
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check class distribution in training and validation sets\n",
        "def check_class_distribution(y_train, y_val):\n",
        "    unique_train, counts_train = np.unique(y_train, return_counts=True)\n",
        "    unique_val, counts_val = np.unique(y_val, return_counts=True)\n",
        "    print(\"Training set class distribution:\", dict(zip(unique_train, counts_train)))\n",
        "    print(\"Validation set class distribution:\", dict(zip(unique_val, counts_val)))\n",
        "\n",
        "check_class_distribution(y_train, y_val)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Training set class distribution: {0: 121324}\nValidation set class distribution: {0: 30331}\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1723015395869
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List of models to evaluate\n",
        "models = {\n",
        "    \"XGBoost\": XGBClassifier(objective='binary:logistic', random_state=42),\n",
        "    \"RandomForest\": RandomForestClassifier(random_state=42),\n",
        "    \"LogisticRegression\": LogisticRegression(max_iter=1000, random_state=42),\n",
        "    \"SVM\": SVC(random_state=42)\n",
        "}\n",
        "\n",
        "# Evaluate each model and log results with MLflow\n",
        "for model_name, model in models.items():\n",
        "    with mlflow.start_run(run_name=model_name):\n",
        "        # Train the model\n",
        "        model.fit(X_train, y_train)\n",
        "        \n",
        "        # Make predictions\n",
        "        y_pred = model.predict(X_val)\n",
        "        \n",
        "        # Evaluate the model\n",
        "        accuracy = accuracy_score(y_val, y_pred)\n",
        "        report = classification_report(y_val, y_pred)\n",
        "        \n",
        "        # Log model, parameters, and metrics\n",
        "        mlflow.sklearn.log_model(model, \"model\")\n",
        "        mlflow.log_params(model.get_params())\n",
        "        mlflow.log_metric(\"accuracy\", accuracy)\n",
        "        \n",
        "        # Print the evaluation report\n",
        "        print(f\"Model: {model_name}\")\n",
        "        print(f\"Accuracy: {accuracy}\")\n",
        "        print(report)\n",
        "        print(\"=\"*80)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Model: XGBoost\nAccuracy: 1.0\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00     30331\n\n    accuracy                           1.00     30331\n   macro avg       1.00      1.00      1.00     30331\nweighted avg       1.00      1.00      1.00     30331\n\n================================================================================\nModel: RandomForest\nAccuracy: 1.0\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00     30331\n\n    accuracy                           1.00     30331\n   macro avg       1.00      1.00      1.00     30331\nweighted avg       1.00      1.00      1.00     30331\n\n================================================================================\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/_distutils_hack/__init__.py:11: UserWarning: Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n  warnings.warn(\n/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/_distutils_hack/__init__.py:26: UserWarning: Setuptools is replacing distutils.\n  warnings.warn(\"Setuptools is replacing distutils.\")\n"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[7], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_name, model \u001b[38;5;129;01min\u001b[39;00m models\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m mlflow\u001b[38;5;241m.\u001b[39mstart_run(run_name\u001b[38;5;241m=\u001b[39mmodel_name):\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m         \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m         \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n\u001b[1;32m     16\u001b[0m         y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_val)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1301\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1299\u001b[0m classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[1;32m   1300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_classes \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m-> 1301\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1302\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis solver needs samples of at least 2 classes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1303\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m in the data, but the data contains only one\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1304\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m class: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m classes_[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1305\u001b[0m     )\n\u001b[1;32m   1307\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m   1308\u001b[0m     n_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
            "\u001b[0;31mValueError\u001b[0m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0"
          ]
        }
      ],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1723015423091
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}