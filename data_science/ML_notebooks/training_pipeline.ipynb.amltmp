{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from azureml.core import Workspace\n",
        "import os\n",
        "import io\n",
        "from azure.storage.blob import BlobServiceClient\n",
        "from sklearn.model_selection import train_test_split\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 1,
          "data": {
            "text/plain": "True"
          },
          "metadata": {}
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1723300480355
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_dataframe_to_blob(dataframe, container_name, blob_name):\n",
        "    # Get connection string from environment variables\n",
        "    connection_string = os.getenv('connection_string')\n",
        "    if not connection_string:\n",
        "        raise ValueError(\"connection_string is not set in the .env file\")\n",
        "    # Initialize BlobServiceClient\n",
        "    try:\n",
        "        blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n",
        "        print(\"Successfully connected to Azure Blob Storage.\")\n",
        "    except ValueError as e:\n",
        "        print(f\"Error initializing BlobServiceClient: {e}\")\n",
        "        raise\n",
        "    # Ensure the container exists\n",
        "    try:\n",
        "        container_client = blob_service_client.get_container_client(container_name)\n",
        "        if not container_client.exists():\n",
        "            container_client.create_container()\n",
        "            print(f\"Created container: {container_name}\")\n",
        "        else:\n",
        "            print(f\"Container {container_name} already exists.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error creating/getting container client: {e}\")\n",
        "        raise\n",
        "    # Convert dataframe to CSV string\n",
        "    csv_data = dataframe.to_csv(index=False)\n",
        "    # Upload CSV string to blob storage\n",
        "    try:\n",
        "        blob_client = container_client.get_blob_client(blob_name)\n",
        "        blob_client.upload_blob(csv_data, overwrite=True)\n",
        "        print(f\"Uploaded {blob_name} to blob storage in container {container_name}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error uploading blob: {e}\")\n",
        "        raise\n",
        "\n",
        "\n",
        "def load_dataframe_from_blob(container_name, blob_name):\n",
        "    \"\"\"\n",
        "    Loads a CSV file from Azure Blob Storage into a Pandas DataFrame.\n",
        "    Args:\n",
        "        container_name (str): The name of the Azure Blob Storage container.\n",
        "        blob_name (str): The name of the blob to download.\n",
        "    Returns:\n",
        "        pandas.DataFrame: The loaded DataFrame.\n",
        "    \"\"\"\n",
        "    # Get connection string from environment variables\n",
        "    connection_string = os.getenv('connection_string')\n",
        "    if not connection_string:\n",
        "        raise ValueError(\"connection_string is not set in the .env file\")\n",
        "    # Initialize BlobServiceClient\n",
        "    try:\n",
        "        blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n",
        "        print(\"Successfully connected to Azure Blob Storage.\")\n",
        "    except ValueError as e:\n",
        "        print(f\"Error initializing BlobServiceClient: {e}\")\n",
        "        raise\n",
        "    # Get blob client\n",
        "    try:\n",
        "        blob_client = blob_service_client.get_blob_client(container=container_name, blob=blob_name)\n",
        "    except Exception as e:\n",
        "        print(f\"Error getting blob client: {e}\")\n",
        "        raise\n",
        "    # Download blob content to a byte stream\n",
        "    download_stream = blob_client.download_blob()\n",
        "    blob_data = download_stream.readall()\n",
        "    # Create a Pandas DataFrame from the byte stream\n",
        "    df = pd.read_csv(io.BytesIO(blob_data))\n",
        "    return df"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1723300591554
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "connection_string = os.getenv('connection_string')\n",
        "container_name = os.getenv('container_name')\n",
        "blob_name = os.getenv('train_blob_name')"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1723300595233
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_processed = load_dataframe_from_blob('processed-files','processed_train_df.csv')\n",
        "print(df_train_processed.shape)\n",
        "print('')\n",
        "df_train_processed.head()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Successfully connected to Azure Blob Storage.\n(455401, 11)\n\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/plain": "                                UserID  basket_icon_click  basket_add_list  \\\n0  a720-6b732349-a720-4862-bd21-644732                  0                0   \n1  a0c0-6b73247c-a0c0-4bd9-8baa-797356                  0                0   \n2  86a8-6b735c67-86a8-407b-ba24-333055                  0                0   \n3  6a3d-6b736346-6a3d-4085-934b-396834                  0                0   \n4  b74a-6b737717-b74a-45c3-8c6a-421140                  0                1   \n\n   basket_add_detail  image_picker  list_size_dropdown  \\\n0                  0             0                   0   \n1                  0             0                   0   \n2                  0             0                   0   \n3                  0             0                   0   \n4                  0             0                   1   \n\n   closed_minibasket_click  sign_in  saw_checkout  saw_homepage  ordered  \n0                        0        0             0             0        0  \n1                        0        0             0             0        0  \n2                        0        0             0             0        0  \n3                        0        0             0             0        0  \n4                        0        1             1             1        1  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>UserID</th>\n      <th>basket_icon_click</th>\n      <th>basket_add_list</th>\n      <th>basket_add_detail</th>\n      <th>image_picker</th>\n      <th>list_size_dropdown</th>\n      <th>closed_minibasket_click</th>\n      <th>sign_in</th>\n      <th>saw_checkout</th>\n      <th>saw_homepage</th>\n      <th>ordered</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>a720-6b732349-a720-4862-bd21-644732</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>a0c0-6b73247c-a0c0-4bd9-8baa-797356</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>86a8-6b735c67-86a8-407b-ba24-333055</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6a3d-6b736346-6a3d-4085-934b-396834</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>b74a-6b737717-b74a-45c3-8c6a-421140</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1723300598682
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_processed[\"ordered\"].value_counts"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": "<bound method IndexOpsMixin.value_counts of 0         0\n1         0\n2         0\n3         0\n4         1\n         ..\n455396    0\n455397    0\n455398    0\n455399    0\n455400    0\nName: ordered, Length: 455401, dtype: int64>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1723021706531
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df_train_processed.drop(columns=['UserID','ordered'])\n",
        "y = df_train_processed['ordered']\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42,stratify=y)"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1723300609010
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check class distribution in training and validation sets\n",
        "def check_class_distribution(y_train, y_val):\n",
        "    unique_train, counts_train = np.unique(y_train, return_counts=True)\n",
        "    unique_val, counts_val = np.unique(y_val, return_counts=True)\n",
        "    print(\"Training set class distribution:\", dict(zip(unique_train, counts_train)))\n",
        "    print(\"Validation set class distribution:\", dict(zip(unique_val, counts_val)))\n",
        "\n",
        "check_class_distribution(y_train, y_val)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Training set class distribution: {0: 349046, 1: 15274}\nValidation set class distribution: {0: 87262, 1: 3819}\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1723292418500
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vanilla Models"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the function to apply models\n",
        "def apply_model(model, X_train, y_train, X_val, y_val, drop_id_col_list):\n",
        "    # Fit the model\n",
        "    model.fit(X_train.drop(drop_id_col_list, axis=1, errors='ignore'), y_train)\n",
        "\n",
        "    # Make predictions\n",
        "    y_train_pred = model.predict(X_train.drop(drop_id_col_list, axis=1, errors='ignore'))\n",
        "    y_pred = model.predict(X_val.drop(drop_id_col_list, axis=1, errors='ignore'))\n",
        "\n",
        "    # Calculate performance metrics\n",
        "    accuracy_train = accuracy_score(y_train, y_train_pred)\n",
        "    accuracy_val = accuracy_score(y_val, y_pred)\n",
        "    f1_train = f1_score(y_train,y_train_pred)\n",
        "    f1_val = f1_score(y_val, y_pred)\n",
        "    return accuracy_train, accuracy_val,f1_train,f1_val\n"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1723292504074
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the models\n",
        "vanila_models = [\n",
        "    (\"Logistic Regression\", LogisticRegression(random_state=321)),\n",
        "    (\"Decision Tree\", DecisionTreeClassifier(random_state=321)),\n",
        "    (\"Random Forest\", RandomForestClassifier(random_state=321)),\n",
        "    (\"XGB Classifier\", XGBClassifier(random_state=321))\n",
        "]"
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1723292594964
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#id col not to be considered while training\n",
        "drop_id_col_list = ['UserID','ordered']\n",
        "\n",
        "# Applying the models and storing the results\n",
        "results_model_name = []\n",
        "results_accuracy_val = []\n",
        "results_f1_score_val = []\n",
        "results_accuracy_train = []\n",
        "results_f1_score_train = []\n",
        "\n",
        "for name, model in vanila_models:\n",
        "    accuracy_train, accuracy_val,f1_train,f1_val = apply_model(model, X_train, y_train, X_val, y_val,drop_id_col_list)\n",
        "    results_model_name.append(name)\n",
        "    results_accuracy_train.append(accuracy_train)\n",
        "    results_accuracy_val.append(accuracy_val)\n",
        "    results_f1_score_train.append(f1_train)\n",
        "    results_f1_score_val.append(f1_val)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/anaconda/envs/azureml_py38/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[12:32:24] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
        }
      ],
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1723293150960
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_df = pd.DataFrame(columns=['Model_Name',\n",
        "                                   'Accuracy_Train','Accuracy_Val',\n",
        "                                   'F1_Score_Train','F1_Score_Val'])\n",
        "\n",
        "results_df['Model_Name'] = results_model_name\n",
        "results_df['Accuracy_Train'] = results_accuracy_train\n",
        "results_df['Accuracy_Val'] = results_accuracy_val\n",
        "results_df['F1_Score_Train'] = results_f1_score_train\n",
        "results_df['F1_Score_Val'] = results_f1_score_val\n",
        "\n",
        "print(results_df.to_string())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "            Model_Name  Accuracy_Train  Accuracy_Val  F1_Score_Train  F1_Score_Val\n0  Logistic Regression        0.973210      0.973167        0.681960      0.679853\n1        Decision Tree        0.975220      0.975253        0.738576      0.736805\n2        Random Forest        0.975220      0.975297        0.738698      0.737395\n3       XGB Classifier        0.975217      0.975330        0.738963      0.738325\n"
        }
      ],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1723293156842
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, X_train, y_train, X_val, y_val, drop_id_col_list):\n",
        "   model.fit(X_train.drop(drop_id_col_list, axis=1, errors='ignore'), y_train)\n",
        "   y_pred_train = model.predict(X_train.drop(drop_id_col_list, axis=1, errors='ignore'))\n",
        "   y_pred_val = model.predict(X_val.drop(drop_id_col_list, axis=1, errors='ignore'))\n",
        "\n",
        "   f1_train = f1_score(y_train, y_pred_train)\n",
        "   accuracy_train = accuracy_score(y_train, y_pred_train)\n",
        "\n",
        "   f1_val = f1_score(y_val, y_pred_val)\n",
        "   accuracy_val = accuracy_score(y_val, y_pred_val)\n",
        "\n",
        "   print(\"Training Set:\")\n",
        "   print(\"F1-score:\", f1_train)\n",
        "   print(\"Accuracy:\", accuracy_train)\n",
        "   print(\"\\nValidation Set:\")\n",
        "   print(\"F1-score:\", f1_val)\n",
        "   print(\"Accuracy:\", accuracy_val)"
      ],
      "outputs": [],
      "execution_count": 21,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1723294294313
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Experiment Tracking"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment name\n",
        "experiment_name = \"Azure_Propensity_Model\"\n",
        "mlflow.set_experiment(experiment_name)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "2024/08/10 12:42:04 INFO mlflow.tracking.fluent: Experiment with name 'Azure_Propensity_Model' does not exist. Creating a new experiment.\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 15,
          "data": {
            "text/plain": "<Experiment: artifact_location='', creation_time=1723293725726, experiment_id='e50b013a-522b-4df2-b552-1787132ac6e8', last_update_time=None, lifecycle_stage='active', name='Azure_Propensity_Model', tags={}>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 15,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1723293722984
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Experiment 1: Logistic Regression**\n",
        "- Set Search Space\n",
        "- Write Objective function\n",
        "- Train LR and fetch best Params\n",
        "- fit the final model\n",
        "- Evaluate Results\n",
        "- Log Model to MLflow"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define hyperparameter spaces for each classifier\n",
        "space_lr = {\n",
        "    'C': hp.loguniform('C', np.log(0.01), np.log(10)),\n",
        "    'max_iter': hp.uniform('max_iter', 1,5000)\n",
        "}"
      ],
      "outputs": [],
      "execution_count": 35,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1723295048797
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def train_evaluate(params):\n",
        "    # Define columns to drop from the dataset\n",
        "    drop_id_col_list = ['UserID','ordered']\n",
        "\n",
        "    # Create a LogisticRegression model with the given parameters\n",
        "    model = LogisticRegression(**params, random_state=321)\n",
        "    \n",
        "    # Train the model\n",
        "    model.fit(X_train.drop(drop_id_col_list, axis=1, errors='ignore'), y_train)\n",
        "    \n",
        "    # Evaluate the model\n",
        "    y_pred = model.predict(X_val.drop(drop_id_col_list, axis=1, errors='ignore'))\n",
        "    score = f1_score(y_val, y_pred)\n",
        "    \n",
        "    return -score  # Minimize the negative of F1-score\n"
      ],
      "outputs": [],
      "execution_count": 36,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1723295051294
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Trials for hyperparameter optimization\n",
        "trials = Trials()\n",
        "\n",
        "# Use Hyperopt to search for the best hyperparameters\n",
        "best_LR_param = fmin(fn=train_evaluate, space=space_lr, algo=tpe.suggest, max_evals=10, trials=trials)\n",
        "\n",
        "print(\"Best hyperparameters:\", best_LR_param)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "100%|██████████| 10/10 [00:11<00:00,  1.13s/trial, best loss: -0.6798532879224521]\nBest hyperparameters: {'C': 2.3330541258369792, 'max_iter': 1470.762397734738}\n"
        }
      ],
      "execution_count": 37,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1723295064894
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_lr = LogisticRegression(**best_LR_param)\n",
        "model_lr.fit(X_train.drop(drop_id_col_list, axis=1, errors='ignore'), y_train)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 38,
          "data": {
            "text/plain": "LogisticRegression(C=2.3330541258369792, max_iter=1470.762397734738)",
            "text/html": "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=2.3330541258369792, max_iter=1470.762397734738)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=2.3330541258369792, max_iter=1470.762397734738)</pre></div></div></div></div></div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 38,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1723295076330
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_model(model_lr,X_train,y_train,X_val,y_val,drop_id_col_list)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Training Set:\nF1-score: 0.68198110133594\nAccuracy: 0.9732103645147123\n\nValidation Set:\nF1-score: 0.6798532879224521\nAccuracy: 0.9731667416914614\n"
        }
      ],
      "execution_count": 41,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1723295093537
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Start an MLflow run\n",
        "mlflow.set_experiment('Azure_Propensity_Model')\n",
        "\n",
        "with mlflow.start_run(run_name=\"LogisticReg_classifier_azure_mlops\") as run:\n",
        "    # Log the best hyperparameters\n",
        "    mlflow.log_params(best_LR_param)\n",
        "    \n",
        "    # Train the final model with the best hyperparameters\n",
        "    best_model = LogisticRegression(**best_LR_param, random_state=321)\n",
        "    best_model.fit(X_train, y_train)\n",
        "    \n",
        "    # Evaluate the model on the test dataset\n",
        "    y_pred = best_model.predict(X_val)\n",
        "    \n",
        "    # Log model performance metrics\n",
        "    f1 = f1_score(y_val, y_pred)\n",
        "    accuracy = accuracy_score(y_val, y_pred)\n",
        "    y_pred_prob = best_model.predict_proba(X_val)[:, 1]\n",
        "    auc_roc = roc_auc_score(y_val, y_pred_prob)\n",
        "\n",
        "    mlflow.log_metric(\"f1_score\", f1)\n",
        "    mlflow.log_metric(\"accuracy\", accuracy)\n",
        "    mlflow.log_metric(\"auc_roc\", auc_roc)\n",
        "    \n",
        "    # Log the shapes of training and testing data\n",
        "    mlflow.log_param(\"train_shape\", X_train.shape)\n",
        "    mlflow.log_param(\"test_shape\", X_val.shape)\n",
        "    \n",
        "    # Plot and log the ROC curve\n",
        "    fpr, tpr, _ = roc_curve(y_val, y_pred_prob)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, label=f\"AUC-ROC (area = {auc_roc:.2f})\")\n",
        "    plt.xlabel(\"False Positive Rate\")\n",
        "    plt.ylabel(\"True Positive Rate\")\n",
        "    plt.title(\"ROC Curve\")\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.grid(True)\n",
        "    \n",
        "    # Save the plot as a temporary file\n",
        "    plt_path = \"roc_curve.png\"\n",
        "    plt.savefig(plt_path)\n",
        "    \n",
        "    # Log the ROC curve\n",
        "    mlflow.log_artifact(plt_path)\n",
        "    \n",
        "    # Log the trained model\n",
        "    mlflow.sklearn.log_model(best_model, \"LogisticReg_classifier_azure_mlops\")\n",
        "\n",
        "    plt.close()\n",
        "\n",
        "print(\"Model and metrics logged in MLflow successfully.\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/anaconda/envs/azureml_py38/lib/python3.9/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n  warnings.warn(\"Setuptools is replacing distutils.\")\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Model and metrics logged in MLflow successfully.\n"
        }
      ],
      "execution_count": 42,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1723295615531
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Experiment 2: RandomForestClassifier**\n",
        "- Set Search Space\n",
        "- Write Objective function\n",
        "- Train LR and fetch best Params\n",
        "- fit the final model\n",
        "- Evaluate Results\n",
        "- Log Model to MLflow"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the search space for RandomForestClassifier\n",
        "search_space_rf = {\n",
        "    # 'n_estimators': hp.choice('n_estimators', [50, 100, 150, 200]),\n",
        "    'max_depth': hp.choice('max_depth', [None, 10, 20, 30]),\n",
        "    'min_samples_split': hp.choice('min_samples_split', [2, 5, 10]),\n",
        "    # 'min_samples_leaf': hp.choice('min_samples_leaf', [1, 2, 4]),\n",
        "    'bootstrap': hp.choice('bootstrap', [True, False])\n",
        "}\n",
        "\n",
        "def train_evaluate_rf(params):\n",
        "    # Create a RandomForest model\n",
        "    model = RandomForestClassifier(**params, random_state=321)\n",
        "    \n",
        "    # Train the model\n",
        "    model.fit(X_train, y_train)\n",
        "    \n",
        "    # Evaluate the model\n",
        "    y_pred = model.predict(X_val)\n",
        "    score = f1_score(y_val, y_pred)\n",
        "    \n",
        "    return -score  # Minimize the negative of F1-score\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 49,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1723297156577
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Trials for hyperparameter optimization\n",
        "trials_rf = Trials()\n",
        "\n",
        "# Use Hyperopt to search for the best hyperparameters\n",
        "best_rf_param = fmin(fn=train_evaluate_rf, space=search_space_rf, algo=tpe.suggest, max_evals=10, trials=trials_rf)\n",
        "\n",
        "print(\"Best hyperparameters for RandomForestClassifier:\", best_rf_param)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "100%|██████████| 10/10 [00:55<00:00,  5.51s/trial, best loss: -0.7378731343283582]\nBest hyperparameters for RandomForestClassifier: {'bootstrap': 0, 'max_depth': 2, 'min_samples_split': 2}\n"
        }
      ],
      "execution_count": 50,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1723297214671
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_rf = RandomForestClassifier(**best_rf_param)\n",
        "model_rf.fit(X_train.drop(drop_id_col_list, axis=1, errors='ignore'), y_train)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 51,
          "data": {
            "text/plain": "RandomForestClassifier(bootstrap=0, max_depth=2)",
            "text/html": "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(bootstrap=0, max_depth=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(bootstrap=0, max_depth=2)</pre></div></div></div></div></div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 51,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1723297229528
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_model(model_rf,X_train,y_train,X_val,y_val,drop_id_col_list)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Training Set:\nF1-score: 0.6544429730739194\nAccuracy: 0.9720657663592446\n\nValidation Set:\nF1-score: 0.654828575331239\nAccuracy: 0.9722554649158441\n"
        }
      ],
      "execution_count": 52,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1723297239505
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve\n",
        "\n",
        "# Start an MLflow run\n",
        "mlflow.set_experiment('Azure_Propensity_Model')\n",
        "\n",
        "with mlflow.start_run(run_name=\"RandomForest_classifier_azure_mlops\") as run:\n",
        "     # Log the best hyperparameters\n",
        "    mlflow.log_params(best_rf_param)\n",
        "    \n",
        "    # Train the final model with the best hyperparameters\n",
        "    best_rf_model = RandomForestClassifier(**best_rf_param, random_state=321)\n",
        "    best_rf_model.fit(X_train, y_train)\n",
        "    \n",
        "    # Evaluate the model on the test dataset\n",
        "    y_pred = best_rf_model.predict(X_val)\n",
        "    y_pred_prob = best_rf_model.predict_proba(X_val)[:, 1]\n",
        "    \n",
        "    f1 = f1_score(y_val, y_pred)\n",
        "    accuracy = accuracy_score(y_val, y_pred)\n",
        "    auc_roc = roc_auc_score(y_val, y_pred_prob)\n",
        "\n",
        "    mlflow.log_metric(\"f1_score\", f1)\n",
        "    mlflow.log_metric(\"accuracy\", accuracy)\n",
        "    mlflow.log_metric(\"auc_roc\", auc_roc)\n",
        "    \n",
        "    # Log the shapes of training and testing data\n",
        "    mlflow.log_param(\"train_shape\", X_train.shape)\n",
        "    mlflow.log_param(\"test_shape\", X_val.shape)\n",
        "    \n",
        "    # Plot and log the ROC curve\n",
        "    fpr, tpr, _ = roc_curve(y_val, y_pred_prob)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, label=f\"AUC-ROC (area = {auc_roc:.2f})\")\n",
        "    plt.xlabel(\"False Positive Rate\")\n",
        "    plt.ylabel(\"True Positive Rate\")\n",
        "    plt.title(\"ROC Curve\")\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.grid(True)\n",
        "    \n",
        "    # Save the plot as a temporary file\n",
        "    plt_path = \"roc_curve_rf.png\"\n",
        "    plt.savefig(plt_path)\n",
        "    \n",
        "    # Log the ROC curve\n",
        "    mlflow.log_artifact(plt_path)\n",
        "    \n",
        "    # Log the trained model\n",
        "    mlflow.sklearn.log_model(best_rf_model, \"RandomForest_classifier_azure_mlops\")\n",
        "\n",
        "    plt.close()\n",
        "\n",
        "print(\"RandomForestClassifier model and metrics logged in MLflow successfully.\")\n"
      ],
      "outputs": [],
      "execution_count": 53,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Experiment 3: XGB Classifier**\n",
        "- Set Search Space\n",
        "- Write Objective function\n",
        "- Train XGB and fetch best Params\n",
        "- fit the final model\n",
        "- Evaluate Results\n",
        "- Log Model to MLflow"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the search space for XGBClassifier\n",
        "search_space_xgb = {\n",
        "    \"max_depth\": hp.choice(\"max_depth\", [3, 4, 5, 6, 7, 8, 10, 11, 12, 15, 20]),\n",
        "    \"gamma\": hp.uniform(\"gamma\", 0, 0.5),\n",
        "    \"subsample\": hp.uniform(\"subsample\", 0.1, 1),\n",
        "    \"colsample_bytree\": hp.uniform(\"colsample_bytree\", 0.1, 1),\n",
        "    \"reg_alpha\": hp.loguniform(\"reg_alpha\", np.log(0.01), np.log(1)),\n",
        "    \"learning_rate\": hp.uniform(\"learning_rate\", 0.01, 0.3),\n",
        "    \"n_estimators\": hp.choice(\"n_estimators\", [50, 100, 150, 200])\n",
        "}\n",
        "\n",
        "def train_evaluate_xgb(params):\n",
        "    # Create an XGBoost model\n",
        "    model = XGBClassifier(**params, random_state=321)\n",
        "    \n",
        "    # Train the model\n",
        "    model.fit(X_train, y_train)\n",
        "    \n",
        "    # Evaluate the model\n",
        "    y_pred = model.predict(X_val)\n",
        "    score = f1_score(y_val, y_pred)\n",
        "    \n",
        "    return -score  # Minimize the negative of F1-score"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1723300726718
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Trials for hyperparameter optimization\n",
        "trials_xgb = Trials()\n",
        "\n",
        "# Use Hyperopt to search for the best hyperparameters\n",
        "best_xgb_param = fmin(fn=train_evaluate_xgb, space=search_space_xgb, algo=tpe.suggest, max_evals=10, trials=trials_xgb)\n",
        "\n",
        "print(\"Best hyperparameters for XGBClassifier:\", best_xgb_param)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[14:39:12] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[14:39:17] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[14:39:24] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[14:39:31] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[14:39:33] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[14:39:37] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[14:39:45] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[14:39:47] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[14:39:49] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[14:40:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n100%|██████████| 10/10 [01:10<00:00,  7.09s/trial, best loss: -0.7388772420218962]\nBest hyperparameters for XGBClassifier: {'colsample_bytree': 0.6946168806919474, 'gamma': 0.17896666259351585, 'learning_rate': 0.07544316777072983, 'max_depth': 5, 'n_estimators': 2, 'reg_alpha': 0.028069902145371535, 'subsample': 0.5840809213581819}\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/anaconda/envs/azureml_py38/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n\n/anaconda/envs/azureml_py38/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n\n/anaconda/envs/azureml_py38/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n\n/anaconda/envs/azureml_py38/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n\n/anaconda/envs/azureml_py38/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n\n/anaconda/envs/azureml_py38/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n\n/anaconda/envs/azureml_py38/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n\n/anaconda/envs/azureml_py38/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n\n/anaconda/envs/azureml_py38/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n\n/anaconda/envs/azureml_py38/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1723300814417
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drop_id_col_list = ['UserID','ordered']\n",
        "model_xgb = XGBClassifier(**best_xgb_param)\n",
        "model_xgb.fit(X_train.drop(drop_id_col_list, axis=1, errors='ignore'), y_train)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/anaconda/envs/azureml_py38/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[14:42:29] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 10,
          "data": {
            "text/plain": "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n              colsample_bynode=1, colsample_bytree=0.6946168806919474,\n              enable_categorical=False, gamma=0.17896666259351585, gpu_id=-1,\n              importance_type=None, interaction_constraints='',\n              learning_rate=0.07544316777072983, max_delta_step=0, max_depth=5,\n              min_child_weight=1, missing=nan, monotone_constraints='()',\n              n_estimators=2, n_jobs=4, num_parallel_tree=1, predictor='auto',\n              random_state=0, reg_alpha=0.028069902145371535, reg_lambda=1,\n              scale_pos_weight=1, subsample=0.5840809213581819,\n              tree_method='exact', validate_parameters=1, verbosity=None)",
            "text/html": "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, colsample_bylevel=1,\n              colsample_bynode=1, colsample_bytree=0.6946168806919474,\n              enable_categorical=False, gamma=0.17896666259351585, gpu_id=-1,\n              importance_type=None, interaction_constraints=&#x27;&#x27;,\n              learning_rate=0.07544316777072983, max_delta_step=0, max_depth=5,\n              min_child_weight=1, missing=nan, monotone_constraints=&#x27;()&#x27;,\n              n_estimators=2, n_jobs=4, num_parallel_tree=1, predictor=&#x27;auto&#x27;,\n              random_state=0, reg_alpha=0.028069902145371535, reg_lambda=1,\n              scale_pos_weight=1, subsample=0.5840809213581819,\n              tree_method=&#x27;exact&#x27;, validate_parameters=1, verbosity=None)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, colsample_bylevel=1,\n              colsample_bynode=1, colsample_bytree=0.6946168806919474,\n              enable_categorical=False, gamma=0.17896666259351585, gpu_id=-1,\n              importance_type=None, interaction_constraints=&#x27;&#x27;,\n              learning_rate=0.07544316777072983, max_delta_step=0, max_depth=5,\n              min_child_weight=1, missing=nan, monotone_constraints=&#x27;()&#x27;,\n              n_estimators=2, n_jobs=4, num_parallel_tree=1, predictor=&#x27;auto&#x27;,\n              random_state=0, reg_alpha=0.028069902145371535, reg_lambda=1,\n              scale_pos_weight=1, subsample=0.5840809213581819,\n              tree_method=&#x27;exact&#x27;, validate_parameters=1, verbosity=None)</pre></div></div></div></div></div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1723300946738
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "# Start an MLflow run\n",
        "mlflow.set_experiment('Azure_Propensity_Model')\n",
        "\n",
        "with mlflow.start_run(run_name=\"XGBClassifier_classifier_azure_mlops\") as run:\n",
        "    # Log the best hyperparameters\n",
        "    mlflow.log_params(best_xgb_param)\n",
        "    \n",
        "    # Train the final model with the best hyperparameters\n",
        "    best_xgb_model = XGBClassifier(**best_xgb_param, random_state=321)\n",
        "    best_xgb_model.fit(X_train, y_train)\n",
        "    \n",
        "    # Evaluate the model on the test dataset\n",
        "    y_pred = best_xgb_model.predict(X_val)\n",
        "    y_pred_prob = best_xgb_model.predict_proba(X_val)[:, 1]\n",
        "    \n",
        "    f1 = f1_score(y_val, y_pred)\n",
        "    accuracy = accuracy_score(y_val, y_pred)\n",
        "    auc_roc = roc_auc_score(y_val, y_pred_prob)\n",
        "\n",
        "    mlflow.log_metric(\"f1_score\", f1)\n",
        "    mlflow.log_metric(\"accuracy\", accuracy)\n",
        "    mlflow.log_metric(\"auc_roc\", auc_roc)\n",
        "    \n",
        "    # Log the shapes of training and testing data\n",
        "    mlflow.log_param(\"train_shape\", X_train.shape)\n",
        "    mlflow.log_param(\"test_shape\", X_val.shape)\n",
        "    \n",
        "    # Plot and log the ROC curve\n",
        "    fpr, tpr, _ = roc_curve(y_val, y_pred_prob)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, label=f\"AUC-ROC (area = {auc_roc:.2f})\")\n",
        "    plt.xlabel(\"False Positive Rate\")\n",
        "    plt.ylabel(\"True Positive Rate\")\n",
        "    plt.title(\"ROC Curve\")\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.grid(True)\n",
        "    \n",
        "    # Save the plot as a temporary file\n",
        "    plt_path = \"roc_curve_xgb.png\"\n",
        "    plt.savefig(plt_path)\n",
        "    \n",
        "    # Log the ROC curve\n",
        "    mlflow.log_artifact(plt_path)\n",
        "    \n",
        "    # Log the trained model\n",
        "    mlflow.xgboost.log_model(best_xgb_model, \"XGBClassifier_classifier_azure_mlops\")\n",
        "\n",
        "    plt.close()\n",
        "\n",
        "print(\"XGBClassifier model and metrics logged in MLflow successfully.\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/anaconda/envs/azureml_py38/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n/anaconda/envs/azureml_py38/lib/python3.9/site-packages/xgboost/sklearn.py:585: UserWarning: n_estimators is not saved in Scikit-Learn meta.\n  warnings.warn(str(k) + ' is not saved in Scikit-Learn meta.', UserWarning)\n/anaconda/envs/azureml_py38/lib/python3.9/site-packages/xgboost/sklearn.py:585: UserWarning: max_depth is not saved in Scikit-Learn meta.\n  warnings.warn(str(k) + ' is not saved in Scikit-Learn meta.', UserWarning)\n/anaconda/envs/azureml_py38/lib/python3.9/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n  warnings.warn(\"Setuptools is replacing distutils.\")\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[14:56:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\nXGBClassifier model and metrics logged in MLflow successfully.\n"
        }
      ],
      "execution_count": 14,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1723301781839
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save Train and Val Datasets"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = X_train.copy()\n",
        "df_train['target'] = y_train\n",
        "\n",
        "df_train.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 15,
          "data": {
            "text/plain": "        basket_icon_click  basket_add_list  basket_add_detail  image_picker  \\\n285320                  0                0                  1             0   \n436118                  0                1                  0             0   \n358099                  0                0                  0             0   \n234310                  0                0                  0             0   \n205949                  0                0                  0             0   \n\n        list_size_dropdown  closed_minibasket_click  sign_in  saw_checkout  \\\n285320                   0                        0        1             1   \n436118                   0                        0        0             0   \n358099                   1                        0        0             0   \n234310                   0                        0        0             0   \n205949                   0                        0        0             0   \n\n        saw_homepage  target  \n285320             0       1  \n436118             0       0  \n358099             1       0  \n234310             1       0  \n205949             0       0  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>basket_icon_click</th>\n      <th>basket_add_list</th>\n      <th>basket_add_detail</th>\n      <th>image_picker</th>\n      <th>list_size_dropdown</th>\n      <th>closed_minibasket_click</th>\n      <th>sign_in</th>\n      <th>saw_checkout</th>\n      <th>saw_homepage</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>285320</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>436118</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>358099</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>234310</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>205949</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 15,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1723302431686
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_val = X_val.copy()\n",
        "df_val['target'] = y_val\n",
        "\n",
        "df_val.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 16,
          "data": {
            "text/plain": "        basket_icon_click  basket_add_list  basket_add_detail  image_picker  \\\n244581                  0                0                  0             0   \n431431                  0                0                  0             0   \n349315                  0                0                  0             0   \n198441                  0                0                  0             0   \n154462                  0                0                  0             0   \n\n        list_size_dropdown  closed_minibasket_click  sign_in  saw_checkout  \\\n244581                   0                        0        0             0   \n431431                   1                        0        0             0   \n349315                   0                        0        0             0   \n198441                   0                        0        0             0   \n154462                   1                        0        0             0   \n\n        saw_homepage  target  \n244581             0       0  \n431431             1       0  \n349315             0       0  \n198441             0       0  \n154462             0       0  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>basket_icon_click</th>\n      <th>basket_add_list</th>\n      <th>basket_add_detail</th>\n      <th>image_picker</th>\n      <th>list_size_dropdown</th>\n      <th>closed_minibasket_click</th>\n      <th>sign_in</th>\n      <th>saw_checkout</th>\n      <th>saw_homepage</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>244581</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>431431</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>349315</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>198441</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>154462</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 16,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1723302478803
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "save_dataframe_to_blob(df_train,'processed-files','model_train_data.csv')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Successfully connected to Azure Blob Storage.\nContainer processed-files already exists.\nUploaded model_train_data.csv to blob storage in container processed-files\n"
        }
      ],
      "execution_count": 17,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1723302499313
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "save_dataframe_to_blob(df_val,'processed-files','model_val_data.csv')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Successfully connected to Azure Blob Storage.\nContainer processed-files already exists.\nUploaded model_val_data.csv to blob storage in container processed-files\n"
        }
      ],
      "execution_count": 18,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1723302501768
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.19",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}